# Specific remote enclave-only configuration

MODELS=`[
  {
    "name": "TheBloke/Llama-2-70B-chat-GPTQ",
    "is_local": false,
    "type": "text-generation",
    "userMessageToken": "[INST]",
    "assistantMessageToken": "[/INST]",
    "messageEndToken": "</s>",
    "preprompt": "[INST]<<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<</SYS>>\n\n[/INST]",
    "promptExamples": [
      {
        "title": "Explaining commits example",
        "prompt": "I want you to act as Senior full stack developer. You have long experience working with colleagues, and know perfectly well how to handle commits from colleagues.\r\n\r\nYou are provided a commit request and have to explain what the proposed modifications do.\r\nHere is the original code:\r\n\"\"\"\r\nsentry.queue.client\r\n~~~~~~~~~~~~~~~~~~~\r\n\r\n:copyright: (c) 2010 by the Sentry Team, see AUTHORS for more details.\r\n:license: BSD, see LICENSE for more details.\r\n\"\"\"\r\nfrom kombu import BrokerConnection\r\nfrom kombu.common import maybe_declare\r\nfrom kombu.pools import producers\r\n\r\nfrom sentry.conf import settings\r\nfrom sentry.queue.queues import task_queues, task_exchange\r\n\r\n\r\nclass Broker(object):\r\n    def __init__(self, config):\r\n        self.connection = BrokerConnection(**config)\r\n\r\n    def delay(self, func, *args, **kwargs):\r\n        payload = {\r\n            \"func\": func,\r\n            \"args\": args,\r\n            \"kwargs\": kwargs,\r\n        }\r\n\r\n        with producers[self.connection].acquire(block=False) as producer:\r\n            for queue in task_queues:\r\n                maybe_declare(queue, producer.channel)\r\n            producer.publish(payload,\r\n                exchange=task_exchange,\r\n                serializer=\"pickle\",\r\n                compression=\"bzip2\",\r\n                queue='default',\r\n                routing_key='default',\r\n            )\r\n\r\nbroker = Broker(settings.QUEUE)\r\n\r\nHere is the proposed code:\r\n\"\"\"\r\nsentry.queue.client\r\n~~~~~~~~~~~~~~~~~~~\r\n\r\n:copyright: (c) 2010 by the Sentry Team, see AUTHORS for more details.\r\n:license: BSD, see LICENSE for more details.\r\n\"\"\"\r\nfrom kombu import BrokerConnection\r\nfrom kombu.common import maybe_declare\r\nfrom kombu.pools import producers\r\n\r\nfrom sentry.conf import settings\r\nfrom sentry.queue.queues import task_queues, task_exchange\r\n\r\n\r\nclass Broker(object):\r\n    def __init__(self, config):\r\n        self.connection = BrokerConnection(**config)\r\n        with producers[self.connection].acquire(block=False) as producer:\r\n            for queue in task_queues:\r\n                maybe_declare(queue, producer.channel)\r\n\r\n    def delay(self, func, *args, **kwargs):\r\n        payload = {\r\n            \"func\": func,\r\n            \"args\": args,\r\n            \"kwargs\": kwargs,\r\n        }\r\n\r\n        with producers[self.connection].acquire(block=False) as producer:\r\n            producer.publish(payload,\r\n                exchange=task_exchange,\r\n                serializer=\"pickle\",\r\n                compression=\"bzip2\",\r\n                queue='default',\r\n                routing_key='default',\r\n            )\r\n\r\nbroker = Broker(settings.QUEUE)\r\n\r\nHere is the commit message:\r\nDeclare queues when broker is instantiated"
      },
      {
        "title": "Documenting code example",
        "prompt": "Can you add comments and documentation to this Python function to handle concurrent requests?\r\n\r\nimport concurrent.futures\r\nimport requests\r\n\r\ndef fetch_url(url):\r\n    response = requests.get(url)\r\n    return response.text\r\n\r\ndef handle_concurrent_requests(urls, max_workers=5):\r\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\r\n        future_to_url = {executor.submit(fetch_url, url): url for url in urls}\r\n        responses = []\r\n        for future in concurrent.futures.as_completed(future_to_url):\r\n            responses.append(future.result())\r\n    return responses\r\n\r\nurls = ['https:\/\/httpbin.org\/get', 'https:\/\/httpbin.org\/ip']\r\nresponses = handle_concurrent_requests(urls)\r\nfor response in responses:\r\n    print(response)"
      },
      {
        "title": "Boilerplate code example",
        "prompt": "Can you propose an example of boilerplate code for a server in Python using gRPC?"
      }
    ],
    "server_addr" : "https://api.chat.mithrilsecurity.io",
    "parameters": {
      "temperature": 0.8,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 2048,
      "max_new_tokens": 2048
    }
  }
]`

PUBLIC_SHOW_LOCAL_MODELS_WARNING=false
PUBLIC_ANNOUNCEMENT_BANNERS=`[]`